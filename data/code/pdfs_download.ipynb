{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9001468c",
   "metadata": {},
   "source": [
    "DOWNLOADING THE PDFS FOR ICCS & JOCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cb979",
   "metadata": {},
   "source": [
    "# ICCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea58d0e",
   "metadata": {},
   "source": [
    "ICCS 2001-2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2220fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, time, requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "DBLP_DIR = Path(os.getenv(\"DBLP_DIR\"))\n",
    "INPUT_JSONL = DBLP_DIR/\"interim\"/\"iccs\"/\"iccs_dblp_dois.jsonl\"\n",
    "OUTDIR = Path(os.getenv(\"ICCS_PDF_DIR\"))\n",
    "LOG_PATH = Path(os.getenv(\"DATA_DIR\"))/\"logs\"/\"iccs_download_status.csv\"\n",
    "WORKERS = 4 \n",
    "\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_json(INPUT_JSONL, lines=True)\n",
    "df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "# Focus on ICCS Springer years (2001-2009)\n",
    "df = df[(df['year'] >= 2001) & (df['year'] <= 2009)].drop_duplicates(subset=['doi'])\n",
    "\n",
    "# Resume\n",
    "if LOG_PATH.exists():\n",
    "    log_df = pd.read_csv(LOG_PATH)\n",
    "    done_dois = set(log_df[log_df['outcome'] == 'downloaded']['doi'].astype(str))\n",
    "    df = df[~df['doi'].isin(done_dois)]\n",
    "\n",
    "tasks = df[['doi', 'year']].to_records(index=False)\n",
    "print(f\"Tasks to process: {len(tasks)}\")\n",
    "\n",
    "# DOWNLOAD\n",
    "def download_paper(doi, year):\n",
    "    doi = doi.strip()\n",
    "    # Filename\n",
    "    fname = f\"{year}_{doi.replace('/', '_').replace(':', '_')}.pdf\"\n",
    "    fpath = OUTDIR / str(year) / fname\n",
    "    fpath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Skip if file exists\n",
    "    if fpath.exists() and fpath.stat().st_size > 30000:\n",
    "        return {\"doi\": doi, \"outcome\": \"skipped\"}\n",
    "\n",
    "    # Try Springer Direct first, then DOI resolver\n",
    "    urls = [f\"https://link.springer.com/content/pdf/{doi}.pdf\", f\"https://doi.org/{doi}\"]\n",
    "    \n",
    "    for url in urls:\n",
    "        try:\n",
    "            r = requests.get(url, timeout=30, headers={\"User-Agent\": \"Mozilla/5.0\"}, allow_redirects=True)\n",
    "            if r.status_code == 200 and r.content[:4] == b\"%PDF\":\n",
    "                fpath.write_bytes(r.content)\n",
    "                return {\"doi\": doi, \"outcome\": \"downloaded\", \"url\": url}\n",
    "        except Exception:\n",
    "            continue\n",
    "    return {\"doi\": doi, \"outcome\": \"failed\"}\n",
    "\n",
    "# EXECUTION\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "    future_to_doi = {executor.submit(download_paper, t[0], t[1]): t[0] for t in tasks}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_doi), total=len(tasks), desc=\"Downloading\"):\n",
    "        res = future.result()\n",
    "        results.append(res)\n",
    "        \n",
    "        # Log\n",
    "        with open(LOG_PATH, 'a', encoding='utf-8') as f:\n",
    "            if f.tell() == 0: f.write(\"doi,outcome,url\\n\")\n",
    "            f.write(f\"{res['doi']},{res['outcome']},{res.get('url','')}\\n\")\n",
    "\n",
    "print(f\"Finished. Check your folder: {OUTDIR.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71e485",
   "metadata": {},
   "source": [
    "ICCS 2010-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174529ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "ELS_API_KEY = os.getenv(\"ELS_API_KEY\")\n",
    "PDF_DIR = os.getenv(\"ICCS_PDF_DIR\")\n",
    "\n",
    "assert ELS_API_KEY, \"ELS_API_KEY missing\"\n",
    "assert PDF_DIR, \"ICCS_PDF_DIR missing\"\n",
    "\n",
    "DBLP_DIR = Path(os.getenv(\"DBLP_DIR\"))\n",
    "IN_PATH = DBLP_DIR/\"interim\"/\"iccs\"/\"iccs_dblp_dois.jsonl\"\n",
    "BASE_OUT_DIR = Path(PDF_DIR)\n",
    "BASE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_URL = \"https://api.elsevier.com/content/article/doi/\"\n",
    "session = requests.Session()\n",
    "\n",
    "print(\"Scanning input file to calculate total tasks\")\n",
    "tasks = []\n",
    "with IN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            rec = json.loads(line)\n",
    "            year = int(rec.get(\"year\", 0))\n",
    "            doi = rec.get(\"doi_normalized\", \"\")\n",
    "            if 2010 <= year <= 2017 and doi.startswith(\"10.1016/j.procs.\"):\n",
    "                tasks.append(rec)\n",
    "        except: continue\n",
    "\n",
    "print(f\"Total papers to process: {len(tasks)}\")\n",
    "\n",
    "#Tqdm\n",
    "for rec in tqdm(tasks, desc=\"Downloading ICCS Papers\"):\n",
    "    doi = rec.get(\"doi_normalized\")\n",
    "    year = str(rec.get(\"year\"))\n",
    "\n",
    "    # Folder\n",
    "    year_dir = BASE_OUT_DIR / year\n",
    "    year_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    fname = f\"{year}_{doi.replace('/', '_')}.pdf\"\n",
    "    fpath = year_dir / fname\n",
    "\n",
    "    if fpath.exists():\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        r = session.get(\n",
    "            BASE_URL + doi,\n",
    "            headers={\"X-ELS-APIKey\": ELS_API_KEY, \"Accept\": \"application/pdf\"},\n",
    "            timeout=60,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            content = r.content \n",
    "            if content[:4] == b\"%PDF\":\n",
    "                fpath.write_bytes(content)\n",
    "\n",
    "        elif r.status_code != 200:\n",
    "            print(f\" [!] Failed {doi}: HTTP {r.status_code}\")\n",
    "\n",
    "    except (requests.exceptions.RequestException, requests.exceptions.ChunkedEncodingError) as e:\n",
    "        print(f\" [!] Network Error: {doi} - {e}\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    time.sleep(1.5) \n",
    "\n",
    "print(f\"All downloads finished. Files are in: {BASE_OUT_DIR.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae92ea05",
   "metadata": {},
   "source": [
    "ICCS 2018-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd076d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "PDF_DIR = os.getenv(\"ICCS_PDF_DIR\")\n",
    "DBLP_DIR = Path(os.getenv(\"DBLP_DIR\"))\n",
    "IN_PATH = DBLP_DIR/\"interim\"/\"iccs\"/\"iccs_dblp_dois.jsonl\"\n",
    "BASE_OUT_DIR = Path(PDF_DIR)\n",
    "BASE_OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "tasks_by_year = {}\n",
    "with IN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            rec = json.loads(line)\n",
    "            year = int(rec.get(\"year\", 0))\n",
    "            if 2018 <= year <= 2025:\n",
    "                tasks_by_year.setdefault(year, []).append(rec)\n",
    "        except: continue\n",
    "\n",
    "for year in sorted(tasks_by_year.keys()):\n",
    "    year_dir = BASE_OUT_DIR / str(year)\n",
    "    year_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    archive_url = f'https://www.iccs-meeting.org/archive/iccs{year}/'\n",
    "    print(f\"\\nICCS {year}...\")\n",
    "\n",
    "    try:\n",
    "        resp = session.get(archive_url, timeout=30)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    except Exception as e:\n",
    "        print(f\"Page load failed: {e}\")\n",
    "        continue\n",
    "\n",
    "    for rec in tqdm(tasks_by_year[year], desc=f\"ICCS {year}\"):\n",
    "        doi = rec.get(\"doi_normalized\", \"\")\n",
    "        if not doi: continue\n",
    "\n",
    "        fname = f\"{year}_{doi.replace('/', '_')}.pdf\"\n",
    "        fpath = year_dir / fname\n",
    "        if fpath.exists(): continue\n",
    "\n",
    "        doi_pattern = re.escape(doi)\n",
    "        elements_with_doi = soup.find_all(string=re.compile(doi_pattern))\n",
    "        \n",
    "        pdf_url = None\n",
    "        for text_node in elements_with_doi:\n",
    "            container = text_node.find_parent(['div', 'p', 'tr', 'td'])\n",
    "            if container:\n",
    "                pdf_link = container.find('a', href=re.compile(r'papers/.*\\.pdf'))\n",
    "                if not pdf_link:\n",
    "                    pdf_link = container.parent.find('a', href=re.compile(r'papers/.*\\.pdf'))\n",
    "                if pdf_link:\n",
    "                    pdf_url = pdf_link['href']\n",
    "                    break\n",
    "\n",
    "        if pdf_url:\n",
    "            if not pdf_url.startswith('http'):\n",
    "                pdf_url = archive_url + pdf_url.lstrip('/')\n",
    "            \n",
    "            try:\n",
    "                r = session.get(pdf_url, timeout=60, stream=True)\n",
    "                if r.status_code == 200 and r.content[:4] == b'%PDF':\n",
    "                    fpath.write_bytes(r.content)\n",
    "            except: pass\n",
    "        else:\n",
    "            print(f\"No PDF for {doi}\")\n",
    "\n",
    "        time.sleep(0.3)\n",
    "\n",
    "print(f\"Complete! Files in: {BASE_OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d88eab",
   "metadata": {},
   "source": [
    "# JOCS 2010-2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "ELS_API_KEY = os.getenv(\"ELS_API_KEY\")\n",
    "PDF_DIR = os.getenv(\"JOCS_PDF_DIR\")\n",
    "\n",
    "assert ELS_API_KEY, \"ELS_API_KEY missing\"\n",
    "assert PDF_DIR, \"JOCS_PDF_DIR missing\"\n",
    "\n",
    "DBLP_DIR = Path(os.getenv(\"DBLP_DIR\"))\n",
    "IN_PATH = DBLP_DIR/\"interim\"/\"jocs\"/\"jocs_dblp_dois.jsonl\"\n",
    "OUT_DIR = Path(PDF_DIR)\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_URL = \"https://api.elsevier.com/content/article/doi/\"\n",
    "\n",
    "results = []\n",
    "session = requests.Session()\n",
    "\n",
    "with IN_PATH.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        rec = json.loads(line)\n",
    "        doi = rec.get(\"doi_normalized\")\n",
    "        year = rec.get(\"year\")\n",
    "\n",
    "        # skip if year missing or >= 2026\n",
    "        if not year or int(year) >= 2026:\n",
    "            continue\n",
    "\n",
    "        if not doi or not doi.startswith(\"10.1016/j.jocs.\"):\n",
    "            continue\n",
    "\n",
    "        fname = f\"{year}_{doi.replace('/', '_')}.pdf\"\n",
    "        fpath = OUT_DIR / fname\n",
    "\n",
    "        if fpath.exists():\n",
    "            continue\n",
    "\n",
    "        print(f\"[{i}] downloading {doi}\")\n",
    "\n",
    "        r = session.get(\n",
    "            BASE_URL + doi,\n",
    "            headers={\n",
    "                \"X-ELS-APIKey\": ELS_API_KEY,\n",
    "                \"Accept\": \"application/pdf\"\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "\n",
    "        if r.status_code == 200 and r.content[:4] == b\"%PDF\":\n",
    "            fpath.write_bytes(r.content)\n",
    "            results.append({\"doi\": doi, \"success\": True})\n",
    "            print(\"  saved\")\n",
    "        else:\n",
    "            results.append({\"doi\": doi, \"success\": False, \"status\": r.status_code})\n",
    "            print(\"  failed\")\n",
    "\n",
    "        time.sleep(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RI_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
